{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnDE_9HRihwV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "import math\n",
        "data_train=pd.read_csv(r\"/content/drive/MyDrive/trainMnist.csv\")\n",
        "data_test=pd.read_csv(r\"/content/drive/MyDrive/trainMnist.csv\")\n",
        "\n",
        "data_train=np.array(data_train)\n",
        "data_test=np.array(data_test)\n",
        "\n",
        "nb_exemple,nb_pixels=data_train.shape\n",
        "nb_exemple_test,nb_pixels_test=data_test.shape\n",
        "\n",
        "np.random.shuffle(data_train)\n",
        "np.random.shuffle(data_test)\n",
        "\n",
        "data_train=data_train.T\n",
        "Y_train=data_train[0]\n",
        "X_train=data_train[1:nb_pixels]\n",
        "X_train=X_train/255.\n",
        "\n",
        "data_test=data_test.T\n",
        "Y_test=data_test[0]\n",
        "X_test=data_test[1:nb_pixels_test]\n",
        "X_test=X_test/255.\n",
        "\n",
        "\n",
        "def init_params():\n",
        "    W1 = np.random.rand(10, 784) - 0.5\n",
        "    b1 = np.random.rand(10, 1) - 0.5\n",
        "    W2 = np.random.rand(10, 10) - 0.5\n",
        "    b2 = np.random.rand(10, 1) - 0.5\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "def ReLU(Z):\n",
        "    return np.maximum(Z, 0)\n",
        "\n",
        "def softmax(Z):\n",
        "    A = np.exp(Z) / sum(np.exp(Z))\n",
        "    return A\n",
        "\n",
        "def forward_prop(W1,b1,W2,b2,X):\n",
        "    Z1=W1.dot(X) + b1\n",
        "    A1=ReLU(Z1)\n",
        "    Z2=W2.dot(A1) + b2\n",
        "    A2=softmax(Z2)\n",
        "    return Z1,A1,Z2,A2\n",
        "\n",
        "def one_hot(Y):\n",
        "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
        "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
        "    one_hot_Y = one_hot_Y.T\n",
        "    return one_hot_Y\n",
        "\n",
        "\n",
        "def ReLU_deriv(Z):\n",
        "    return Z > 0\n",
        "def backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y):\n",
        "    one_hot_Y = one_hot(Y)\n",
        "    #erruer\n",
        "    dZ2 = A2 - one_hot_Y\n",
        "    #calculer deriver d'erruer hidden layer 2\n",
        "    dW2 = 1 / 1000 * dZ2.dot(A1.T)\n",
        "    db2 = 1 / 1000 * np.sum(dZ2)\n",
        "    dZ1 = W2.T.dot(dZ2) * ReLU_deriv(Z1)\n",
        "    dW1 = 1 / 1000 * dZ1.dot(X.T)\n",
        "    db1 = 1 / 1000 * np.sum(dZ1)\n",
        "    return dW1, db1, dW2, db2\n",
        "\n",
        "#methode gradient\n",
        "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
        "    W1 = W1 - alpha * dW1\n",
        "    b1 = b1 - alpha * db1\n",
        "    W2 = W2 - alpha * dW2\n",
        "    b2 = b2 - alpha * db2\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "#methode momentieum\n",
        "def update_parametrs(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha,beta,dV1,dV2,dVB1,dVB2):\n",
        "    dV1=beta*dV1+(1-beta)*dW1\n",
        "    W1 = W1 - alpha * dV1\n",
        "\n",
        "    dVB1=beta*dVB1+(1-beta)*db1\n",
        "    b1 = b1 - alpha * dVB1\n",
        "\n",
        "    dV2=beta*dV2+(1-beta)*dW2\n",
        "    W2 = W2 - alpha * dV2\n",
        "\n",
        "    dVB2 = beta * dVB2 + (1 - beta) * db2\n",
        "    b2 = b2 - alpha * dVB2\n",
        "    return W1, b1, W2, b2,dV1,dV2,dVB1,dVB2\n",
        "\n",
        "def get_predictions(A2):\n",
        "    return np.argmax(A2, 0)\n",
        "\n",
        "def get_accuracy(predictions, Y):\n",
        "    # print(predictions, Y)\n",
        "    return np.sum(predictions == Y) / Y.size\n",
        "\n",
        "def loss_function(Y_train,Y_pre):\n",
        "    one_hot_Y = one_hot(Y_train)\n",
        "    return 0.5 * np.mean((Y_pre - one_hot_Y) ** 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***`Adam`***"
      ],
      "metadata": {
        "id": "8eGmld4F4c5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha, v1, v2, vb1,vb2,m1,m2,mb1,mb2,v1c,v2c,vb1c,vb2c,m1c,m2c,mb1c,mb2c):\n",
        "    alpha = 0.001\n",
        "    beta1 = 0.9\n",
        "    beta2 = 0.999\n",
        "    eps = 1e-8\n",
        "    #\n",
        "    # v1=v1+dW1**2\n",
        "    # v2=v2+dW2**2\n",
        "    # vb1=vb1+db1**2\n",
        "    # vb2=vb2+db2**2\n",
        "\n",
        "    # vraiiiiiiiiiii\n",
        "\n",
        "    # Update the weights and biases\n",
        "    W1 -= alpha * m1c / (np.sqrt(v1c) + eps)\n",
        "    W2 -= alpha * m2c / (np.sqrt(v2c) + eps)\n",
        "    b1 -= alpha * mb1c / (np.sqrt(vb1c) + eps)\n",
        "    b2 -= alpha * mb2c / (np.sqrt(vb2c) + eps)\n",
        "\n",
        "    # W1 = W1 - alpha * m1c * 1 / np.sqrt(v1c + eps)\n",
        "    # W2 = W2 - alpha * m2c * 1 / np.sqrt(v2c + eps)\n",
        "    # b1 = b1 - alpha * mb1c * 1 / np.sqrt(vb1c + eps)\n",
        "    # b2 = b2 - alpha * mb2c * 1 / np.sqrt(vb2c + eps)\n",
        "    # vraiiiiiiiiiiiii\n",
        "    m1c = m1 / (1 - beta1)\n",
        "    m2c = m2 / (1 - beta1)\n",
        "    mb1c = mb1 / (1 - beta1)\n",
        "    mb2c = mb2 / (1 - beta1)\n",
        "    # vraiiiiiiiiiiiii\n",
        "    v1c = v1 / (1 - beta2)\n",
        "    v2c = v2 / (1 - beta2)\n",
        "    vb1c = vb1 / (1 - beta2)\n",
        "    vb2c = vb2 / (1 - beta2)\n",
        "    # vraiiiiiiii\n",
        "\n",
        "\n",
        "    # m1 = beta1 * m1 + (1 - beta1) * dW1\n",
        "    # m2 = beta1 * m2 + (1 - beta1) * dW2\n",
        "    # mb1 = beta1 * mb1 + (1 - beta1) * db1\n",
        "    # mb2 = beta1 * mb2 + (1 - beta1) * db2\n",
        "    #\n",
        "    # v1 = beta2 * v1 + (1 - beta2) * (dW1**2)\n",
        "    # v2 = beta2 * v2 + (1 - beta2) * (dW2**2)\n",
        "    # vb1 = beta2 * vb1 + (1 - beta2) * (db1**2)\n",
        "    # vb2 = beta2 * vb2 + (1 - beta2) * (db2**2)\n",
        "    m1 = beta1 * m1 + (1 - beta1) * dW1\n",
        "    mb1 = beta1 * mb1 + (1 - beta1) * db1\n",
        "    m2 = beta1 * m2 + (1 - beta1) * dW2\n",
        "    mb2 = beta1* mb2 + (1 - beta1) * db2\n",
        "    # vraiiiiiiii\n",
        "    v1 = beta2 * v1 + (1 - beta2) * (dW1**2)\n",
        "    vb1 = beta2 * vb1 + (1 - beta2) *( db1**2)\n",
        "    v2 = beta2 * v2 + (1 - beta2) * (dW2**2)\n",
        "    vb2 = beta2* vb2 + (1 - beta2) * (db2**2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # beta = 0.9\n",
        "    # W1 = W1 - alpha * v1\n",
        "    # b1 = b1 - alpha * vb1\n",
        "    # W2 = W2 - alpha * v2\n",
        "    # b2 = b2 - alpha * vb2\n",
        "    # v1 = beta * v1 + (1 - beta) * dW1\n",
        "    # vb1 = beta * vb1 + (1 - beta) * db1\n",
        "    # v2 = beta * v2 + (1 - beta) * dW2\n",
        "    # vb2 = beta * vb2 + (1 - beta) * db2\n",
        "\n",
        "    return W1, b1, W2, b2, dW1, db1, dW2, db2, v1, v2, vb1,vb2,m1,m2,mb1,mb2,v1c,v2c,vb1c,vb2c,m1c,m2c,mb1c,mb2c\n",
        "\n",
        "def gradient_descent(X, Y, alpha, iterations):\n",
        "    W1, b1, W2, b2 = init_params()\n",
        "    v1 = np.zeros(W1.shape)\n",
        "    vb1 = np.zeros(b1.shape)\n",
        "    v2 = np.zeros(W2.shape)\n",
        "    vb2 = np.zeros(b2.shape)\n",
        "\n",
        "    v1c = np.zeros(W1.shape)\n",
        "    vb1c = np.zeros(b1.shape)\n",
        "    v2c = np.zeros(W2.shape)\n",
        "    vb2c = np.zeros(b2.shape)\n",
        "\n",
        "    m1c = np.zeros(W1.shape)\n",
        "    mb1c = np.zeros(b1.shape)\n",
        "    m2c = np.zeros(W2.shape)\n",
        "    mb2c = np.zeros(b2.shape)\n",
        "\n",
        "    m1 = np.zeros(W1.shape)\n",
        "    mb1 = np.zeros(b1.shape)\n",
        "    m2 = np.zeros(W2.shape)\n",
        "    mb2 = np.zeros(b2.shape)\n",
        "\n",
        "\n",
        "    for i in range(iterations):\n",
        "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
        "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
        "        W1, b1, W2, b2, dW1, db1, dW2, db2, v1, v2, vb1,vb2,m1,m2,mb1,mb2,v1c,v2c,vb1c,vb2c,m1c,m2c,\\\n",
        "        mb1c,mb2c = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha, v1, v2,\n",
        "                                  vb1,vb2,m1,m2,mb1,mb2,v1c,v2c,vb1c,vb2c,m1c,m2c,mb1c,mb2c)\n",
        "        if i % 10 == 0:\n",
        "            print(\"Iteration: \", i)\n",
        "            predictions = get_predictions(A2)\n",
        "            print(get_accuracy(predictions, Y))\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "\n",
        "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5A6V6UF84cLw",
        "outputId": "2e7385f9-23db-42d5-831d-f9570ddbadb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  0\n",
            "0.14504761904761904\n",
            "Iteration:  10\n",
            "0.18564285714285714\n",
            "Iteration:  20\n",
            "0.28969047619047616\n",
            "Iteration:  30\n",
            "0.34376190476190477\n",
            "Iteration:  40\n",
            "0.40714285714285714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ALgo adagrad"
      ],
      "metadata": {
        "id": "_1wnvMEe5QJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha, v1, v2, vb1, vb2):\n",
        "    eps=0.00000001\n",
        "\n",
        "    v1=v1+dW1**2\n",
        "    v2=v2+dW2**2\n",
        "    vb1=vb1+db1**2\n",
        "    vb2=vb2+db2**2\n",
        "\n",
        "    W1 = W1 - alpha * dW1 *1/ np.sqrt(v1 + eps)\n",
        "    W2 = W2 - alpha * dW2 *1/ np.sqrt(v2 + eps)\n",
        "    b1 = b1 - alpha * db1 *1/ np.sqrt(vb1 + eps)\n",
        "    b2 = b2 - alpha * db2 *1/np.sqrt(vb2 + eps)\n",
        "\n",
        "    # beta = 0.9\n",
        "    # W1 = W1 - alpha * v1\n",
        "    # b1 = b1 - alpha * vb1\n",
        "    # W2 = W2 - alpha * v2\n",
        "    # b2 = b2 - alpha * vb2\n",
        "    # v1 = beta * v1 + (1 - beta) * dW1\n",
        "    # vb1 = beta * vb1 + (1 - beta) * db1\n",
        "    # v2 = beta * v2 + (1 - beta) * dW2\n",
        "    # vb2 = beta * vb2 + (1 - beta) * db2\n",
        "\n",
        "    return W1, b1, W2, b2, v1, v2, vb1, vb2\n",
        "\n",
        "def gradient_descent(X, Y, alpha, iterations):\n",
        "    W1, b1, W2, b2 = init_params()\n",
        "    w11 = np.zeros(W1.shape)\n",
        "    b11 = np.zeros(b1.shape)\n",
        "    w22 = np.zeros(W2.shape)\n",
        "    b22 = np.zeros(b2.shape)\n",
        "    for i in range(iterations):\n",
        "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
        "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
        "        W1, b1, W2, b2, w11, w22, b11, b22 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha, w11, w22, b11,\n",
        "                                                           b22)\n",
        "        if i % 10 == 0:\n",
        "            print(\"Iteration: \", i)\n",
        "            predictions = get_predictions(A2)\n",
        "            print(get_accuracy(predictions, Y))\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "\n",
        "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZBl7_l65SKa",
        "outputId": "690bd4f0-0733-4254-a456-9ad4752a4adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  0\n",
            "0.06278571428571429\n",
            "Iteration:  10\n",
            "0.6269047619047619\n",
            "Iteration:  20\n",
            "0.7666428571428572\n",
            "Iteration:  30\n",
            "0.8136904761904762\n",
            "Iteration:  40\n",
            "0.8375476190476191\n",
            "Iteration:  50\n",
            "0.8595238095238096\n",
            "Iteration:  60\n",
            "0.8718571428571429\n",
            "Iteration:  70\n",
            "0.8811190476190476\n",
            "Iteration:  80\n",
            "0.8872857142857142\n",
            "Iteration:  90\n",
            "0.8887142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RMS **PROP**"
      ],
      "metadata": {
        "id": "UMRI7I0k3JeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha, v1, v2, vb1, vb2):\n",
        "    eps=0.00000001\n",
        "    beta = 0.99\n",
        "    v1=beta*v1+(1-beta)*dW1**2\n",
        "    v2=beta*v2+(1-beta)*dW2**2\n",
        "    vb1=beta*vb1+(1-beta)*db1**2\n",
        "    vb2=beta*vb2+(1-beta)*db2**2\n",
        "    W1 = W1 - alpha * dW1 *1/ np.sqrt(v1 + eps)\n",
        "    W2 = W2 - alpha * dW2 *1/ np.sqrt(v2 + eps)\n",
        "    b1 = b1 - alpha * db1 *1/ np.sqrt(vb1 + eps)\n",
        "    b2 = b2 - alpha * db2 *1/np.sqrt(vb2 + eps)\n",
        "\n",
        "\n",
        "    # W1 = W1 - alpha * v1\n",
        "    # b1 = b1 - alpha * vb1\n",
        "    # W2 = W2 - alpha * v2\n",
        "    # b2 = b2 - alpha * vb2\n",
        "    # v1 = beta * v1 + (1 - beta) * dW1\n",
        "    # vb1 = beta * vb1 + (1 - beta) * db1\n",
        "    # v2 = beta * v2 + (1 - beta) * dW2\n",
        "    # vb2 = beta * vb2 + (1 - beta) * db2\n",
        "\n",
        "    return W1, b1, W2, b2, v1, v2, vb1, vb2\n",
        "\n",
        "def gradient_descent(X, Y, alpha, iterations):\n",
        "    W1, b1, W2, b2 = init_params()\n",
        "    w11 = np.zeros(W1.shape)\n",
        "    b11 = np.zeros(b1.shape)\n",
        "    w22 = np.zeros(W2.shape)\n",
        "    b22 = np.zeros(b2.shape)\n",
        "    for i in range(iterations):\n",
        "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
        "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
        "        W1, b1, W2, b2, w11, w22, b11, b22 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha, w11, w22, b11,\n",
        "                                                           b22)\n",
        "        if i % 10 == 0:\n",
        "            print(\"Iteration: \", i)\n",
        "            predictions = get_predictions(A2)\n",
        "            print(get_accuracy(predictions, Y))\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "\n",
        "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIrQPwSH2zLH",
        "outputId": "f3e8306f-a0c3-459b-a525-60a400430b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  0\n",
            "0.11228571428571428\n",
            "Iteration:  10\n",
            "0.18907142857142858\n",
            "Iteration:  20\n",
            "0.19226190476190477\n",
            "Iteration:  30\n",
            "0.19373809523809524\n",
            "Iteration:  40\n",
            "0.1951190476190476\n",
            "Iteration:  50\n",
            "0.1962142857142857\n",
            "Iteration:  60\n",
            "0.19702380952380952\n",
            "Iteration:  70\n",
            "0.19807142857142856\n",
            "Iteration:  80\n",
            "0.1987857142857143\n",
            "Iteration:  90\n",
            "0.19938095238095238\n",
            "Iteration:  100\n",
            "0.19966666666666666\n",
            "Iteration:  110\n",
            "0.1998095238095238\n",
            "Iteration:  120\n",
            "0.19992857142857143\n",
            "Iteration:  130\n",
            "0.20002380952380952\n",
            "Iteration:  140\n",
            "0.2001904761904762\n",
            "Iteration:  150\n",
            "0.20023809523809524\n",
            "Iteration:  160\n",
            "0.20045238095238097\n",
            "Iteration:  170\n",
            "0.2005952380952381\n",
            "Iteration:  180\n",
            "0.20076190476190475\n",
            "Iteration:  190\n",
            "0.20083333333333334\n",
            "Iteration:  200\n",
            "0.20102380952380952\n",
            "Iteration:  210\n",
            "0.2012857142857143\n",
            "Iteration:  220\n",
            "0.20135714285714285\n",
            "Iteration:  230\n",
            "0.20164285714285715\n",
            "Iteration:  240\n",
            "0.20183333333333334\n",
            "Iteration:  250\n",
            "0.20176190476190475\n",
            "Iteration:  260\n",
            "0.20226190476190475\n",
            "Iteration:  270\n",
            "0.20216666666666666\n",
            "Iteration:  280\n",
            "0.20245238095238094\n",
            "Iteration:  290\n",
            "0.20223809523809524\n",
            "Iteration:  300\n",
            "0.20147619047619048\n",
            "Iteration:  310\n",
            "0.2022857142857143\n",
            "Iteration:  320\n",
            "0.20257142857142857\n",
            "Iteration:  330\n",
            "0.20264285714285715\n",
            "Iteration:  340\n",
            "0.20261904761904762\n",
            "Iteration:  350\n",
            "0.20285714285714285\n",
            "Iteration:  360\n",
            "0.20247619047619048\n",
            "Iteration:  370\n",
            "0.20252380952380952\n",
            "Iteration:  380\n",
            "0.2020952380952381\n",
            "Iteration:  390\n",
            "0.2019047619047619\n",
            "Iteration:  400\n",
            "0.20297619047619048\n",
            "Iteration:  410\n",
            "0.19276190476190477\n",
            "Iteration:  420\n",
            "0.20283333333333334\n",
            "Iteration:  430\n",
            "0.20314285714285715\n",
            "Iteration:  440\n",
            "0.2032857142857143\n",
            "Iteration:  450\n",
            "0.20316666666666666\n",
            "Iteration:  460\n",
            "0.20254761904761906\n",
            "Iteration:  470\n",
            "0.20252380952380952\n",
            "Iteration:  480\n",
            "0.20245238095238094\n",
            "Iteration:  490\n",
            "0.20304761904761906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AdaDelta algorithme **"
      ],
      "metadata": {
        "id": "RRkQsp7-kTi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha, v1, v2, vb1, vb2,D1,D2,Db1,Db2):\n",
        "    w1_old = W1.copy()\n",
        "    w2_old = W2.copy()\n",
        "    b1_old = b1.copy()\n",
        "    b2_old = b2.copy()\n",
        "\n",
        "    eps=0.00000001\n",
        "    beta = 0.9\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #\n",
        "    # v1 = beta * v1 + (1 - beta) *( dW1 ** 2)\n",
        "    # v2 = beta * v2 + (1 - beta) * (dW2 ** 2)\n",
        "    # vb1 = beta * vb1 + (1 - beta) * (db1 ** 2)\n",
        "    # vb2 = beta * vb2 + (1 - beta) * (db2 ** 2)\n",
        "\n",
        "    v1 = beta * v1 + (1 - beta) * (dW1 ** 2)\n",
        "    v2 = beta * v2 + (1 - beta) * (dW2 ** 2)\n",
        "    vb1 = beta * vb1 + (1 - beta) * (db1 ** 2)\n",
        "    vb2 = beta * vb2 + (1 - beta) * (db2 ** 2)\n",
        "\n",
        "\n",
        "\n",
        "    W1 -= (np.sqrt(D1) + eps) * dW1 * 1 / np.sqrt(v1 + eps)\n",
        "    W2 -= (np.sqrt(D2) + eps) * dW2 * 1 / np.sqrt(v2 + eps)\n",
        "    b1 -= (np.sqrt(Db1) + eps) * db1 * 1 / np.sqrt(vb1 + eps)\n",
        "    b2 -= (np.sqrt(Db2) + eps) * db2 * 1 / np.sqrt(vb2 + eps)\n",
        "    # D1 = beta * D1 + (1 - beta) * ((w1_old - W1) ** 2)\n",
        "    # D2 = beta * D2 + (1 - beta) * ((w2_old - W2) ** 2)\n",
        "    # Db1 = beta * Db1 + (1 - beta) *( (b1_old - b1) ** 2)\n",
        "    # Db2 = beta * Db2 + (1 - beta) * ((b2_old - b2) ** 2)\n",
        "    D1 = beta * D1 + (1 - beta) * ((w1_old - W1) ** 2)\n",
        "    D2 = beta * D2 + (1 - beta) * ((w2_old - W2) ** 2)\n",
        "    Db1 = beta * Db1 + (1 - beta) * ((b1_old - b1) ** 2)\n",
        "    Db2 = beta * Db2 + (1 - beta) * ((b2_old - b2) ** 2)\n",
        "\n",
        "\n",
        "    #\n",
        "    # W1 = W1 - (np.sqrt(D1)+eps) * dW1 * 1 / np.sqrt(v1 + eps)\n",
        "    # W2 = W2 - (np.sqrt(D2)+eps) * dW2 * 1 / np.sqrt(v2 + eps)\n",
        "    # b1 = b1 - (np.sqrt(Db1)+eps) * db1 * 1 / np.sqrt(vb1 + eps)\n",
        "    # b2 = b2 - (np.sqrt(Db2)+eps) * db2 * 1 / np.sqrt(vb2 + eps)\n",
        "\n",
        "\n",
        "\n",
        "    # v1=beta*v1+(1-beta)*dW1**2\n",
        "    # v2=beta*v2+(1-beta)*dW2**2\n",
        "    # vb1=beta*vb1+(1-beta)*db1**2\n",
        "    # vb2=beta*vb2+(1-beta)*db2**2\n",
        "\n",
        "\n",
        "\n",
        "    # W1 = W1 - alpha * v1\n",
        "    # b1 = b1 - alpha * vb1\n",
        "    # W2 = W2 - alpha * v2\n",
        "    # b2 = b2 - alpha * vb2\n",
        "    # v1 = beta * v1 + (1 - beta) * dW1\n",
        "    # vb1 = beta * vb1 + (1 - beta) * db1\n",
        "    # v2 = beta * v2 + (1 - beta) * dW2\n",
        "    # vb2 = beta * vb2 + (1 - beta) * db2\n",
        "\n",
        "    return W1, b1, W2, b2, v1, v2, vb1, vb2 ,D1 ,D2 ,Db1 ,Db2\n",
        "\n",
        "\n",
        "def gradient_descent(X, Y, alpha, iterations):\n",
        "    W1, b1, W2, b2 = init_parametrs()\n",
        "    w11 = np.zeros(W1.shape)\n",
        "    b11 = np.zeros(b1.shape)\n",
        "    w22 = np.zeros(W2.shape)\n",
        "    b22 = np.zeros(b2.shape)\n",
        "    D1 = np.zeros(W1.shape)\n",
        "    Db1 = np.zeros(b1.shape)\n",
        "    D2 = np.zeros(W2.shape)\n",
        "    Db2 = np.zeros(b2.shape)\n",
        "    for i in range(iterations):\n",
        "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
        "        dW1, db1, dW2, db2 = backward_prop(Z1, A1, Z2, A2, W1, W2, X, Y)\n",
        "        W1, b1, W2, b2, w11, w22, b11, b22,D1,D2,Db1,Db2= update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha, w11, w22, b11,b22,D1,D2,Db1,Db2)\n",
        "        if i % 10 == 0:\n",
        "            print(\"Iteration: \", i)\n",
        "            predictions = get_predictions(A2)\n",
        "            print(get_accuracy(predictions, Y))\n",
        "    return W1, b1, W2, b2\n",
        "\n",
        "\n",
        "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 0.10, 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ODTdEgIkYJq",
        "outputId": "e0b19e40-5897-43dd-9bdd-e70c9b59594b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  0\n",
            "0.09492857142857143\n",
            "Iteration:  10\n",
            "0.09492857142857143\n",
            "Iteration:  20\n",
            "0.09495238095238095\n",
            "Iteration:  30\n",
            "0.09495238095238095\n",
            "Iteration:  40\n",
            "0.09497619047619048\n",
            "Iteration:  50\n",
            "0.09497619047619048\n",
            "Iteration:  60\n",
            "0.09497619047619048\n",
            "Iteration:  70\n",
            "0.095\n",
            "Iteration:  80\n",
            "0.095\n",
            "Iteration:  90\n",
            "0.095\n"
          ]
        }
      ]
    }
  ]
}